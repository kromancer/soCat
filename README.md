Autogenerated by https://deepwiki.org

# Introduction

soCat orchestrates the evaluation of multiple vision-language models (VLMs) against a common prompt set and image corpus, writing every model’s responses to a shared, lock-protected JSONL file for later analysis. Execution is split into two layers:

1. `launch_all_models.py` acts as a coordinator, sequentially spawning isolated Python subprocesses—one per VLM.  
2. Each subprocess runs `run_model.py`, which loads images, builds structured chat-style messages (system prompt + image), invokes a Hugging Face `transformers` pipeline (`"image-text-to-text"`), and appends results to a common file using a cross-platform file-lock.

Sources: [launch_all_models.py](), [run_model.py]()


## Component Breakdown

### 1. Model Launcher (`launch_all_models.py`)  
| Aspect | Details |
|---|---|
| Model list | `MODELS` includes seven HF model identifiers (e.g., `Qwen/Qwen2-VL-2B-Instruct`). |
| Isolation strategy | Uses `subprocess.run` with the repo’s current Python interpreter, passing model name, HF token, output path, and `--trust-remote-code`. |
| Execution order | Sequential to minimise GPU/CPU contention; a comment notes `Popen` could enable parallelism. |
| Shared output | Timestamped JSONL under `runs/`, created once and reused by all workers. |

Sources: [launch_all_models.py:1-40]()

### 2. Worker Process (`run_model.py`)

#### 2.1 CLI & Configuration  
| Option | Type | Default | Purpose |
|---|---|---|---|
| `--model` | str (required) | — | HF model id/path. |
| `--token` | str | `$HF_TOKEN` env | Auth for private models. |
| `--output` | str | `runs/<ts>__aggregate.jsonl` | Shared results file. |
| `--images` | list[str] | `["./sock.png", "./cat.png"]` | Image paths to evaluate. |
| `--trust-remote-code` | flag | `True` | Allow custom model code. |

Sources: [run_model.py]()

#### 2.2 Image Handling  
`load_images()` iterates over provided paths, opens each with Pillow in RGB mode, and records `(basename, PIL.Image)` tuples. Failures are logged but still inserted (with `None`) to preserve ordering.  
Sources: [run_model.py]()

#### 2.3 Prompt Construction  
Multiple system prompts (`system_prompt` … `system_prompt3`) encode task rules (weight ≤ 1.4 kg, width ≤ 12 cm, avoid living beings, etc.). For every prompt and every image the worker builds a chat message:

```python
def build_messages(system_text, image):
    return [
        {"role": "system",
         "content": [{"type": "text", "text": system_text}]},
        {"role": "user",
         "content": [{"type": "image", "image": image}]},
    ]
```
Sources: [run_model.py]()

#### 2.4 Model Invocation  
The worker initialises a `transformers.pipeline("image-text-to-text")`. Each `(prompt, image)` pair is passed via `pipe(text=messages)`. The helper `extract_text()` normalises diverse return formats (`generated_text`, nested lists, etc.) into a plain string.  
Sources: [run_model.py]()

#### 2.5 Concurrent-Safe Result Storage  
`append_jsonl()` appends result dicts to the shared file with a simple `.lock` scheme:

| Field | Description |
|---|---|
| `timestamp` | `datetime.now().isoformat()` at generation time. |
| `model` | HF model id. |
| `prompt_name` | Identifier of the system prompt used. |
| `image` | Base filename of the evaluated image. |
| `response_text` | Raw model output or error string. |

Sources: [run_model.py]()

---

### 3. Dependency Footprint (`requirements.txt`)

| Package | Minimum Version | Role |
|---|---|---|
| `transformers` | 4.43.0 | VLM pipeline & HF integration. |
| `torch` | 2.1.0 | Backend tensor engine. |
| `torchvision` | — | Image utilities. |
| `Pillow` | 10.0.0 | Image loading/format conversion. |
| `tqdm` | 4.66.0 | (Unused in shown files but declared). |
| `numpy` | 1.25.0 | Numerical helpers. |

Sources: [requirements.txt]()

---

### 4. Ancillary PNG Optimisation Workflow  
The repository documents a helper `scripts/compress_png.sh` used to downsize PNG test images. Although not part of the runtime architecture, optimised assets reduce I/O overhead during model evaluation.

Sources: [compress_png.sh]()
